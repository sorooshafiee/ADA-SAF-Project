{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import folium\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from os import path\n",
    "from time import sleep, time\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "from difflib import get_close_matches\n",
    "from geopy.geocoders import Nominatim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sample.tsv file...\n",
      "is done!\n"
     ]
    }
   ],
   "source": [
    "# Read the csv file\n",
    "print('Reading sample.tsv file...')\n",
    "df = pd.read_csv(\n",
    "    path.join('data', 'sample.tsv'),\n",
    "    sep=\"\\t\",\n",
    "    encoding='utf-8',\n",
    "    escapechar='\\\\',\n",
    "    na_values='N',\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    header=None\n",
    ")\n",
    "print('is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading schema.txt file...\n",
      "is done!\n"
     ]
    }
   ],
   "source": [
    "print('Reading schema.txt file...')\n",
    "schema = pd.read_csv(\n",
    "    path.join('data', 'schema.txt'),\n",
    "    sep=\"\\s+\",\n",
    "    header =None\n",
    ")\n",
    "print('is done!')\n",
    "# Rename the dataframe columns\n",
    "df.columns = schema[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in important columns\n",
    "df.dropna(\n",
    "    subset=['createdAt', 'id', 'placeLatitude', 'placeLongitude', 'userId'],\n",
    "    how='any',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change the string in 'createdAt' column to datetime format\n",
    "df['createdAt'] = pd.to_datetime(\n",
    "    df['createdAt'],\n",
    "    format='%Y-%m-%d %H:%M:%S',\n",
    "    errors='coerce'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove useless columns\n",
    "df = df[['id', 'userId', 'createdAt','placeLatitude','placeLongitude']]\n",
    "# Remove duplicated tweets with the same id\n",
    "if not df['id'].is_unique:\n",
    "    df.drop_duplicates(subset='id', inplace=True)\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to recover the cities location from latitude-longitude pairs, we use two different strategies:\n",
    "\n",
    "1. **online strategy:** we use the geopy API to send a request containing information about the longitude and latitude of a place. The main cumbersome here is that all these kind of online APIs have some kind of request rate limit, and as it is suggested in [its website](http://wiki.openstreetmap.org/wiki/Nominatim_usage_policy), the time between two consecutive request should be more that 1 seconds. This actually makes the online approach so slow. One remedy to accelerate the process is to save longitude-latitude: location pair to a dictionary. Thus, before sending a request, we first check whether we have the location in our dictionary or not.\n",
    "\n",
    "2. **offline strategy:** we can also use the geojson or topojson files for Switzerland and its neighbor countries. The corresponding geofiles are downloaded from the following github repositories:\n",
    "    1. Switzerland topojson file from [swiss_map repo](https://github.com/interactivethings/swiss-maps).\n",
    "    2. France geojson file from [france-geojson repo](https://github.com/gregoiredavid/france-geojson).\n",
    "    3. Italy geojson file from [leaflet-geojson-selector repo](https://github.com/stefanocudini/leaflet-geojson-selector).\n",
    "    4. Germany geojson file from [deutschlandGeoJSON repo](https://github.com/isellsoap/deutschlandGeoJSON)\n",
    "    5. Austria geojson file from [click_that_hood repo](https://github.com/codeforamerica/click_that_hood).\n",
    "    6. Liechtenstein geojson file from [CountryGeoJSONCollection repo](https://github.com/LonnyGomes/CountryGeoJSONCollection).\n",
    "\n",
    "In general, for the offinle strategy, one can also follow this [stackoverflow response](http://stackoverflow.com/questions/6159074/given-the-lat-long-coordinates-how-can-we-find-out-the-city-country/6355183#6355183) or this [one](http://stackoverflow.com/a/24871449/5267664). The first one relies on the geoname database while the second one actually gives us a procedure to find geojson files for any country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Online strategy:\n",
    "We start from the online strategy. The following function find the country together with its state/canton of a location. We will see later that we could do the same thing in the offline approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function for finding a location from the latitude-longitude information using online API\n",
    "geolocator = Nominatim()\n",
    "locations = dict()\n",
    "def online_locating(data):\n",
    "    lat = str(data.placeLatitude)\n",
    "    lng = str(data.placeLongitude)\n",
    "    lookup = ','.join([lat, lng])\n",
    "    if lookup not in set(locations.keys()):\n",
    "        location = geolocator.reverse(lookup, language='en')        \n",
    "        try:\n",
    "            country = location.raw['address']['country_code'].upper()\n",
    "        except:\n",
    "            country = float('NaN')\n",
    "        try:\n",
    "            state = location.raw['address']['state']\n",
    "        except:\n",
    "            try:\n",
    "                state = location.raw['address']['country']\n",
    "            except:\n",
    "                state = float('NaN')\n",
    "        locations[lookup] = {'country': country, 'state': state}\n",
    "        sleep(1) # sleep for 1 sec (required by Nominatim usage policy)\n",
    "    return pd.Series({'country': locations[lookup]['country'],\n",
    "                      'state': locations[lookup]['state']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "df[['country', 'state']] = df.apply(lambda x: online_locating(x), axis=1)\n",
    "elapsed = time() - t\n",
    "print('Elapsed time is ' + str(round(elapsed, 4)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it took very long to even recover locations for the sample file. Hence, it does not make sense to follow the online approach for the actual problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Offline approach:\n",
    "As we mentioned before, it is necessary to download the required geojson/topojson file to run the offline approach. All files are available in data/geofiles folder. In this part, we use [gepandas](http://geopandas.org/) for furthur analysis. The resulting dataframes can be used to find the location of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch_gdf = gpd.read_file(path.join('data/geofiles', 'ch-cantons.json'))\n",
    "fr_gdf = gpd.read_file(path.join('data/geofiles', 'france-states.geojson'))\n",
    "it_gdf = gpd.read_file(path.join('data/geofiles', 'italy-states.json'))\n",
    "de_gdf = gpd.read_file(path.join('data/geofiles', 'germany-states.geojson'))\n",
    "at_gdf = gpd.read_file(path.join('data/geofiles', 'austria-states.geojson'))\n",
    "li_gdf = gpd.read_file(path.join('data/geofiles', 'liechtenstein.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modify dataframes for merging\n",
    "ch_gdf = ch_gdf[['geometry', 'name']]\n",
    "ch_gdf['country'] = 'CH'\n",
    "\n",
    "fr_gdf = fr_gdf[['geometry', 'name']]\n",
    "fr_gdf['country'] = 'FR'\n",
    "\n",
    "it_gdf = it_gdf[['geometry', 'name']]\n",
    "it_gdf['country'] = 'IT'\n",
    "\n",
    "de_gdf = de_gdf[['geometry', 'NAME_1']]\n",
    "de_gdf = de_gdf.rename(columns={'NAME_1': 'name'})\n",
    "de_gdf['country'] = 'DE'\n",
    "\n",
    "at_gdf = at_gdf[['geometry', 'name']]\n",
    "at_gdf['country'] = 'AT'\n",
    "\n",
    "li_gdf = li_gdf[['geometry', 'NAME']]\n",
    "li_gdf = li_gdf.rename(columns={'NAME': 'name'})\n",
    "li_gdf['country'] = 'LI'\n",
    "\n",
    "gdf_poly = pd.concat([ch_gdf, fr_gdf, it_gdf, de_gdf, at_gdf, li_gdf], ignore_index=True)\n",
    "gdf_poly = gdf_poly.rename(columns={'name': 'state'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-tree structure in geopandas dataframe enables us to find the twitters location very fast. The following function find each location is inside which state/canton. A tutorial to show how to take advantages of R-tree structure is available [here](http://geoffboeing.com/2016/10/r-tree-spatial-index-python/#more-2183)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdf_point = gpd.GeoDataFrame(df)\n",
    "gdf_point['geometry'] = df.apply(lambda row: Point(row.placeLongitude, row.placeLatitude), axis=1)\n",
    "gdf_point.crs = gdf_poly.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "gdf_join = gpd.tools.sjoin(gdf_point, gdf_poly, how=\"left\")\n",
    "elapsed = time() - t\n",
    "print('Elapsed time is ' + str(round(elapsed, 4)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdf_join.drop_duplicates(subset='id', inplace=True)\n",
    "gdf_join.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_index = gdf_join['state'].isnull()\n",
    "gdf_join.loc[null_index,['country', 'state']] = gdf_join[null_index].apply(\n",
    "    lambda row: online_locating(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modify_dataframe(row):\n",
    "    countries = set(gdf_poly['country'].unique())\n",
    "    if row['country'] not in countries:\n",
    "        row['state'] = row['country']\n",
    "    else:\n",
    "        sub_gdf = gdf_poly[gdf_poly['country'] == row['country']]\n",
    "        indices = sub_gdf.index\n",
    "        states = sub_gdf.state.values\n",
    "        if 'Bavaria' in row['state']:\n",
    "            row['state'] = 'Bayern'\n",
    "        else:\n",
    "            row['state'] = get_close_matches(row['state'], states, 1, 0)[0]\n",
    "        row['index_right'] = sub_gdf[sub_gdf['state'] == row['state']].index.values[0]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdf_join.loc[null_index,:] = gdf_join[null_index].apply(\n",
    "    lambda row: modify_dataframe(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove tweets from countries which are not in our list\n",
    "gdf_join = gdf_join[gdf_join['index_right'].notnull()]\n",
    "# Reset index\n",
    "gdf_join.reset_index(drop=True, inplace=True)\n",
    "# Convert float number in the index_right column to integer\n",
    "gdf_join['index_right'] = gdf_join['index_right'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch_gdf = gpd.read_file(path.join('data/geofiles', 'ch-cantons.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((8.426435392487207 47.56753522878918,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(POLYGON ((7.22144880383911 46.32921395991143,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((8.412147013965686 47.14074339205419,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((8.678727333238598 46.57919089842064,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((8.571224294838597 46.99016015027388,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(POLYGON ((8.368873639014801 46.78796940836982...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>POLYGON ((8.47197676402881 46.85535968813034, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>POLYGON ((9.004547723461043 47.17314486147242,...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>POLYGON ((8.492978412458852 47.10020175003641,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(POLYGON ((7.051848018785272 46.97712393254112...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(POLYGON ((7.558382377356071 47.32237472492322...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>POLYGON ((7.634088103554214 47.56110668172401,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(POLYGON ((7.436908479957253 47.3799729144173,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(POLYGON ((8.562832707452944 47.5994192300226,...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>POLYGON ((9.342932814796063 47.24933210037475,...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(POLYGON ((9.502962654237075 47.34737241877414...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(POLYGON ((9.476018854739353 47.051798572134, ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>POLYGON ((9.159451890607034 46.16955512227442,...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>POLYGON ((7.956869378345099 47.45520482743998,...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(POLYGON ((8.670471825648386 47.68486118838407...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>POLYGON ((8.384749615149822 46.45215245904929,...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(POLYGON ((6.82105668571388 46.42715476519837,...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>POLYGON ((6.82105668571388 46.42715476519837, ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>POLYGON ((7.039963716649913 46.97987049444512,...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(POLYGON ((6.125643571068145 46.31723258117079...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>POLYGON ((6.861472384960463 47.16562167017015,...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             geometry  id\n",
       "0   POLYGON ((8.426435392487207 47.56753522878918,...   1\n",
       "1   (POLYGON ((7.22144880383911 46.32921395991143,...   2\n",
       "2   POLYGON ((8.412147013965686 47.14074339205419,...   3\n",
       "3   POLYGON ((8.678727333238598 46.57919089842064,...   4\n",
       "4   POLYGON ((8.571224294838597 46.99016015027388,...   5\n",
       "5   (POLYGON ((8.368873639014801 46.78796940836982...   6\n",
       "6   POLYGON ((8.47197676402881 46.85535968813034, ...   7\n",
       "7   POLYGON ((9.004547723461043 47.17314486147242,...   8\n",
       "8   POLYGON ((8.492978412458852 47.10020175003641,...   9\n",
       "9   (POLYGON ((7.051848018785272 46.97712393254112...  10\n",
       "10  (POLYGON ((7.558382377356071 47.32237472492322...  11\n",
       "11  POLYGON ((7.634088103554214 47.56110668172401,...  12\n",
       "12  (POLYGON ((7.436908479957253 47.3799729144173,...  13\n",
       "13  (POLYGON ((8.562832707452944 47.5994192300226,...  14\n",
       "14  POLYGON ((9.342932814796063 47.24933210037475,...  15\n",
       "15  (POLYGON ((9.502962654237075 47.34737241877414...  16\n",
       "16  (POLYGON ((9.476018854739353 47.051798572134, ...  17\n",
       "17  POLYGON ((9.159451890607034 46.16955512227442,...  18\n",
       "18  POLYGON ((7.956869378345099 47.45520482743998,...  19\n",
       "19  (POLYGON ((8.670471825648386 47.68486118838407...  20\n",
       "20  POLYGON ((8.384749615149822 46.45215245904929,...  21\n",
       "21  (POLYGON ((6.82105668571388 46.42715476519837,...  22\n",
       "22  POLYGON ((6.82105668571388 46.42715476519837, ...  23\n",
       "23  POLYGON ((7.039963716649913 46.97987049444512,...  24\n",
       "24  (POLYGON ((6.125643571068145 46.31723258117079...  25\n",
       "25  POLYGON ((6.861472384960463 47.16562167017015,...  26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
