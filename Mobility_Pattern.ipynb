{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "from os import path\n",
    "from time import sleep, time\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import vincenty\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the saved file is as easy as running these lines of code\n",
    "with open('data/cache/' + 'offline_gdf' + '.pkl', 'rb') as f:\n",
    "    obj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj['day'] = obj['createdAt'].map(lambda x: x.day)\n",
    "obj['month'] = obj['createdAt'].map(lambda x: x.month)\n",
    "obj['year'] = obj['createdAt'].map(lambda x: x.year)\n",
    "daily_user = ['userId', 'day', 'month', 'year']\n",
    "obj['daily_tweets'] = obj.groupby(by=daily_user)['userId'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove rows corresponding to people who have less than a threshold value in one day\n",
    "threshold_tweets = 2\n",
    "obj = obj[obj['daily_tweets'] >= threshold_tweets].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_denoising(sub_df, crt_speed = 60):\n",
    "    zipped_columns = sub_df.tolist()\n",
    "    lst = list(zip(*zipped_columns))\n",
    "    lat = lst[0]\n",
    "    lng = lst[1]\n",
    "    tw_time = lst[2]\n",
    "    states = lst[3]\n",
    "    points = list(zip(lat,lng))\n",
    "\n",
    "    if len(sub_df) == 2:\n",
    "        d = vincenty(points[1], points[0]).meters\n",
    "        t = tw_time[1] - tw_time[0]\n",
    "        t = t.total_seconds()\n",
    "        v = d / t if t else float('inf')\n",
    "        if v > crt_speed:\n",
    "            return [float('NaN'), float('NaN')]\n",
    "        else:\n",
    "            return states\n",
    "    else:\n",
    "        orig = points[0:-2]\n",
    "        dest1 = points[1:-1]\n",
    "        dest2 = points[2::]        \n",
    "        denoised = list(states)\n",
    "\n",
    "        for index in range(len(orig)):\n",
    "            d1 = vincenty(dest1[index], orig[index]).meters\n",
    "            t1 = tw_time[index+1] - tw_time[index]\n",
    "            t1 = t1.total_seconds()\n",
    "            v1 = d1 / t1 if t1 else float('inf')\n",
    "            \n",
    "            d2 = vincenty(dest2[index], dest1[index]).meters\n",
    "            t2 = tw_time[index+2] - tw_time[index+1]\n",
    "            t2 = t2.total_seconds()\n",
    "            v2 = d2 / t2 if t2 else float('inf')\n",
    "\n",
    "            d3 = vincenty(dest2[index], orig[index]).meters\n",
    "            t3 = tw_time[index+2] - tw_time[index]\n",
    "            t3 = t3.total_seconds()\n",
    "            v3 = d3 / t3 if t3 else float('inf')\n",
    "            \n",
    "            if np.isinf(v1) | np.isinf(v2) | np.isinf(v3):\n",
    "                denoised = [float('NaN')] * len(denoised)\n",
    "                break\n",
    "            if (v1 > crt_speed) & (v2 > crt_speed):\n",
    "                if v3 <= crt_speed:\n",
    "                    denoised[index+1] = float('NaN')\n",
    "                else:\n",
    "                    denoised[index] = float('NaN')\n",
    "                    denoised[index+1] = float('NaN')\n",
    "                    if index == len(orig) - 1:\n",
    "                        denoised[index+2] = float('NaN')\n",
    "            if (v1 > crt_speed) & (v2 <= crt_speed):\n",
    "                denoised[index] = float('NaN')\n",
    "\n",
    "        return denoised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj['new'] = list(zip(obj['latitude'], obj['longitude'], obj['createdAt'], obj['state']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj['state'] = obj.groupby(by=daily_user)['new'].transform(lambda x: data_denoising(x))\n",
    "obj = obj[obj['state'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to restrict ourselves more in order to find more reasonable results. There are still some traveling patterns which do not make sense as the number of commutes between different cantons are so many. Thus, we will remove all tweets corresponding to a user in a day who has commutes more than a threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_path(sub_df, cmt_num = 10):       \n",
    "    origin = sub_df.values[0:-1]\n",
    "    destination = sub_df.values[1::]\n",
    "    index = origin != destination\n",
    "    path = float('NaN')\n",
    "    if (index.any()) & (sum(index) <= cmt_num):\n",
    "        path = '->'.join(origin[index])\n",
    "        path = '->'.join([path, destination[index][-1]])\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj['daily_pattern'] = obj.groupby(by=daily_user)['state'].transform(lambda x: find_path(x))\n",
    "obj = obj[obj['daily_pattern'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
