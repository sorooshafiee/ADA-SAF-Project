{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pickle\n",
    "from os import path\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "DIR_DATA = path.join('data', 'twitter data')\n",
    "DIR_GEO = path.join('data', 'geofiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the saved file is as easy as running these lines of code\n",
    "with open(path.join(DIR_DATA, 'clean_data.pkl'), 'rb') as in_file:\n",
    "    df = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>1</th>\n",
       "      <th>id</th>\n",
       "      <th>userId</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>text</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>daily_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>2016-09-15 20:48:01</td>\n",
       "      <td>8.96044</td>\n",
       "      <td>46.0027</td>\n",
       "      <td>se lo dici tu... https://t.co/x7Qm1VHBKL</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>4159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>2016-09-15 20:48:05</td>\n",
       "      <td>8.22414</td>\n",
       "      <td>46.8131</td>\n",
       "      <td>https://t.co/noYrTnqmg9</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>4159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2147483648</td>\n",
       "      <td>435239151</td>\n",
       "      <td>2016-09-15 20:48:15</td>\n",
       "      <td>5.94082</td>\n",
       "      <td>47.2010</td>\n",
       "      <td>@BesacTof @Leonid_CCCP Tu dois t'engager en si...</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>2016-09-15 20:48:27</td>\n",
       "      <td>8.96044</td>\n",
       "      <td>46.0027</td>\n",
       "      <td>dillo https://t.co/hScjeZbi4c</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>4159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>2016-09-15 20:48:29</td>\n",
       "      <td>9.64878</td>\n",
       "      <td>45.8865</td>\n",
       "      <td>Miii le voci nere.. Che meraviglia.. #XF10</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>4159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "1          id      userId           createdAt  longitude  latitude  \\\n",
       "0 -2147483648 -2147483648 2016-09-15 20:48:01    8.96044   46.0027   \n",
       "1 -2147483648 -2147483648 2016-09-15 20:48:05    8.22414   46.8131   \n",
       "2 -2147483648   435239151 2016-09-15 20:48:15    5.94082   47.2010   \n",
       "3 -2147483648 -2147483648 2016-09-15 20:48:27    8.96044   46.0027   \n",
       "4 -2147483648 -2147483648 2016-09-15 20:48:29    9.64878   45.8865   \n",
       "\n",
       "1                                               text  day  month  year  \\\n",
       "0           se lo dici tu... https://t.co/x7Qm1VHBKL   15      9  2016   \n",
       "1                            https://t.co/noYrTnqmg9   15      9  2016   \n",
       "2  @BesacTof @Leonid_CCCP Tu dois t'engager en si...   15      9  2016   \n",
       "3                      dillo https://t.co/hScjeZbi4c   15      9  2016   \n",
       "4         Miii le voci nere.. Che meraviglia.. #XF10   15      9  2016   \n",
       "\n",
       "1  daily_tweets  \n",
       "0          4159  \n",
       "1          4159  \n",
       "2            16  \n",
       "3          4159  \n",
       "4          4159  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove noisy tweets with the above function\n",
    "df['new'] = tuple(zip(df['latitude'], df['longitude'], df['createdAt']))\n",
    "not_noisy = df.groupby(by=daily_user)['new'].transform(lambda x: data_denoising(x))\n",
    "df = df[not_noisy].reset_index(drop=True)\n",
    "# Remove the generated column\n",
    "del df['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load geofiles\n",
    "ch_gdf = gpd.read_file(path.join(DIR_GEO, 'ch-cantons.json'))\n",
    "fr_gdf = gpd.read_file(path.join(DIR_GEO, 'france-states.geojson'))\n",
    "it_gdf = gpd.read_file(path.join(DIR_GEO, 'italy-states.json'))\n",
    "de_gdf = gpd.read_file(path.join(DIR_GEO, 'germany-states.geojson'))\n",
    "at_gdf = gpd.read_file(path.join(DIR_GEO, 'austria-states.geojson'))\n",
    "li_gdf = gpd.read_file(path.join(DIR_GEO, 'liechtenstein.geojson'))\n",
    "\n",
    "# Modify dataframes for merging\n",
    "ch_gdf = ch_gdf[['geometry', 'name']]\n",
    "ch_gdf['country'] = 'CH'\n",
    "\n",
    "fr_gdf = fr_gdf[['geometry', 'name']]\n",
    "fr_gdf['country'] = 'FR'\n",
    "\n",
    "it_gdf = it_gdf[['geometry', 'name']]\n",
    "it_gdf['country'] = 'IT'\n",
    "\n",
    "de_gdf = de_gdf[['geometry', 'NAME_1']]\n",
    "de_gdf = de_gdf.rename(columns={'NAME_1': 'name'})\n",
    "de_gdf['country'] = 'DE'\n",
    "\n",
    "at_gdf = at_gdf[['geometry', 'name']]\n",
    "at_gdf['country'] = 'AT'\n",
    "\n",
    "li_gdf = li_gdf[['geometry', 'NAME']]\n",
    "li_gdf = li_gdf.rename(columns={'NAME': 'name'})\n",
    "li_gdf['country'] = 'LI'\n",
    "# Concatinate the dataframes\n",
    "df_poly = pd.concat([ch_gdf, fr_gdf, it_gdf, de_gdf, at_gdf, li_gdf], ignore_index=True)\n",
    "df_poly = df_poly.rename(columns={'name': 'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert our dataframe to a geopandas dataframe\n",
    "df = gpd.GeoDataFrame(df)\n",
    "df['geometry'] = df.apply(lambda row: Point(row.longitude, row.latitude), axis=1)\n",
    "df.crs = df_poly.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Offline locating using spatial indexing in geopandas\n",
    "print('Start spatial merging process...')\n",
    "t = time()\n",
    "df = gpd.tools.sjoin(df, df_poly, how=\"left\")\n",
    "elapsed = time() - t\n",
    "print('Elapsed time is ' + str(round(elapsed, 2)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove unlocated tweets\n",
    "df = df[df['state'].notnull()].reset_index(drop=True)\n",
    "# Remove index_right column\n",
    "del df['index_right']\n",
    "# Drop duplicate tweets. It might be possible that we locate boundaries into two different cantons\n",
    "# df = df.drop_duplicates(subset='id')\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_path(sub_df, cmt_num = 10):       \n",
    "    origin = sub_df.values[0:-1]\n",
    "    destination = sub_df.values[1::]\n",
    "    index = origin != destination\n",
    "    path = float('NaN')\n",
    "    if (index.any()) & (sum(index) <= cmt_num):\n",
    "        path = '->'.join(origin[index])\n",
    "        path = '->'.join([path, destination[index][-1]])\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_patterns = df.groupby(by=daily_user)['state'].apply(lambda x: find_path(x))\n",
    "daily_patterns = daily_patterns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the results with pickle\n",
    "with open(path.join('data', 'daily_patterns.pkl'), 'wb') as in_file:\n",
    "    pickle.dump(daily_patterns, in_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.groupby(by=daily_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
