{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to a study by Pear Analytics [16], about 40% of all the tweets are pointless “babbles” like “have to get something from the minimart downstairs”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import pickle\n",
    "from os import path\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import CMUTweetTagger\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import fastcluster\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIR_DATA = path.join('data', 'twitter data')\n",
    "DIR_GEO = path.join('data', 'geofiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# Loading the saved file is as easy as running these lines of code\n",
    "with open(path.join(DIR_DATA, 'clean_data.pkl'), 'rb') as in_file:\n",
    "    df = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='createdAt', ascending=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we normalize the text, the code is taken from \n",
    "#https://github.com/heerme/twitter-topics/blob/master/twitter-topics-from-json-text-stream.py\n",
    "def normalize_text(text):\n",
    "    if type(text) is not str:\n",
    "        print(text)\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(pic\\.twitter\\.com/[^\\s]+))','', text)\n",
    "    text = re.sub('@[^\\s]+','', text)\n",
    "    text = re.sub('#([^\\s]+)', '', text)\n",
    "    text = re.sub('[:;>?<=*+()/,\\-#!$%\\{˜|\\}\\[^_\\\\@\\]1234567890’‘]',' ', text)\n",
    "    text = re.sub('[\\d]','', text)\n",
    "    text = text.replace(\".\", '')\n",
    "    text = text.replace(\"'\", ' ')\n",
    "    text = text.replace(\"\\\"\", ' ')\n",
    "    #text = text.replace(\"-\", \" \")\n",
    "    #normalize some utf8 encoding\n",
    "    text = text.replace(\"\\x9d\",' ').replace(\"\\x8c\",' ')\n",
    "    text = text.replace(\"\\xa0\",' ')\n",
    "    text = text.replace(\"\\x9d\\x92\", ' ').replace(\"\\x9a\\xaa\\xf0\\x9f\\x94\\xb5\", ' ').replace(\"\\xf0\\x9f\\x91\\x8d\\x87\\xba\\xf0\\x9f\\x87\\xb8\", ' ').replace(\"\\x9f\",' ').replace(\"\\x91\\x8d\",' ')\n",
    "    text = text.replace(\"\\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8\",' ').replace(\"\\xf0\",' ').replace('\\xf0x9f','').replace(\"\\x9f\\x91\\x8d\",' ').replace(\"\\x87\\xba\\x87\\xb8\",' ')\t\n",
    "    text = text.replace(\"\\xe2\\x80\\x94\",' ').replace(\"\\x9d\\xa4\",' ').replace(\"\\x96\\x91\",' ').replace(\"\\xe1\\x91\\xac\\xc9\\x8c\\xce\\x90\\xc8\\xbb\\xef\\xbb\\x89\\xd4\\xbc\\xef\\xbb\\x89\\xc5\\xa0\\xc5\\xa0\\xc2\\xb8\",' ')\n",
    "    text = text.replace(\"\\xe2\\x80\\x99s\", \" \").replace(\"\\xe2\\x80\\x98\", ' ').replace(\"\\xe2\\x80\\x99\", ' ').replace(\"\\xe2\\x80\\x9c\", \" \").replace(\"\\xe2\\x80\\x9d\", \" \")\n",
    "    text = text.replace(\"\\xe2\\x82\\xac\", \" \").replace(\"\\xc2\\xa3\", \" \").replace(\"\\xc2\\xa0\", \" \").replace(\"\\xc2\\xab\", \" \").replace(\"\\xf0\\x9f\\x94\\xb4\", \" \").replace(\"\\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8\\xf0\\x9f\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the hashtags and users\n",
    "df['Hashtags'] = df['text'].apply(lambda x:{tag.strip(\"#\") for tag in x.split() if tag.startswith(\"#\")})\n",
    "df['users'] = df['text'].apply(lambda x:{tag.strip(\"@\") for tag in x.split() if tag.startswith(\"@\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(subset = ['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['processed_text'] = df['text'].apply(lambda x: normalize_text(x))\n",
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.iloc[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  filter the blank cells\n",
    "filter_text = (df[\"processed_text\"] != \"\") & (df[\"processed_text\"] != \" \") & (df[\"processed_text\"] != \"  \") \\\n",
    "    & (df[\"processed_text\"] != \"   \") \n",
    "df = df[filter_text]\n",
    "df.reset_index(inplace=True,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.extend(nltk.corpus.stopwords.words('french'))\n",
    "stop_words.extend(nltk.corpus.stopwords.words('italian'))\n",
    "stop_words.extend(nltk.corpus.stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nltk_tokenize(text):\n",
    "    tokens = []\n",
    "    pos_tokens = []\n",
    "    entities = []\n",
    "    features = []\n",
    "    try:\n",
    "        tokens = tknzr.tokenize(text)\n",
    "        #tokens = text.split()\n",
    "        for word in tokens:\n",
    "            if word.lower() not in stop_words and len(word) > 1:\n",
    "                features.append(word)\n",
    "    except: \n",
    "        pass\n",
    "    return [tokens, pos_tokens, entities, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_tokenize_text(text):\n",
    "    REGEX = re.compile(r\",\\s*\")\n",
    "    tokens = []\n",
    "    for tok in REGEX.split(text):\n",
    "        #if \"@\" not in tok and \"#\" not in tok:\n",
    "        if \"@\" not in tok:\n",
    "            tokens.append(tok.strip().lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 9 tweets (22 tokens) in 0.4 seconds: 24.5 tweets/sec, 59.8 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 9 tweets (22 tokens) in 0.3 seconds: 25.9 tweets/sec, 63.4 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 9 tweets (22 tokens) in 0.4 seconds: 24.0 tweets/sec, 58.7 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 9 tweets (22 tokens) in 0.4 seconds: 25.6 tweets/sec, 62.5 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 9 tweets (22 tokens) in 0.4 seconds: 23.6 tweets/sec, 57.6 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 32.3 tweets/sec, 78.0 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 27.1 tweets/sec, 65.6 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 32.0 tweets/sec, 77.3 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 31.3 tweets/sec, 75.5 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 32.4 tweets/sec, 78.4 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.6 seconds: 20.7 tweets/sec, 49.9 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.5 seconds: 26.7 tweets/sec, 64.4 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 30.9 tweets/sec, 74.7 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 30.4 tweets/sec, 73.4 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 30.2 tweets/sec, 73.0 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.5 seconds: 24.2 tweets/sec, 58.6 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 32.0 tweets/sec, 77.3 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 32.4 tweets/sec, 78.4 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 12 tweets (29 tokens) in 0.4 seconds: 32.1 tweets/sec, 77.5 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HARRY POTTER\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 13 tweets (31 tokens) in 0.4 seconds: 36.8 tweets/sec, 87.8 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HARRY POTTER\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 13 tweets (31 tokens) in 0.3 seconds: 38.1 tweets/sec, 90.9 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HARRY POTTER\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 13 tweets (31 tokens) in 0.3 seconds: 37.6 tweets/sec, 89.6 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HARRY POTTER\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nLOOKS LIKE\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nLOOKS\\tV\\t0.9878\\nLIKE\\tP\\t0.8516\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 14 tweets (33 tokens) in 0.4 seconds: 39.7 tweets/sec, 93.5 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'HARRY POTTER\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nLOOKS LIKE\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'HARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nLOOKS\\tV\\t0.9878\\nLIKE\\tP\\t0.8516\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 14 tweets (33 tokens) in 0.3 seconds: 42.3 tweets/sec, 99.7 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'BAHNHOF WINTERTHUR\\nHARRY POTTER\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nLOOKS LIKE\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE' (b'BAHNHOF\\t^\\t0.8254\\nWINTERTHUR\\t^\\t0.8501\\n\\nHARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nLOOKS\\tV\\t0.9878\\nLIKE\\tP\\t0.8516\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 15 tweets (35 tokens) in 0.4 seconds: 36.6 tweets/sec, 85.4 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'BAHNHOF WINTERTHUR\\nHARRY POTTER\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nLOOKS LIKE\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE\\nZ\\xc3\\x9cRICH HAUPTBAHNHOF' (b'BAHNHOF\\t^\\t0.8254\\nWINTERTHUR\\t^\\t0.8501\\n\\nHARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nLOOKS\\tV\\t0.9878\\nLIKE\\tP\\t0.8516\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\nZ\\xc3\\x9cRICH\\t^\\t0.8980\\nHAUPTBAHNHOF\\t^\\t0.6175\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 16 tweets (37 tokens) in 0.4 seconds: 41.3 tweets/sec, 95.6 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'BAHNHOF WINTERTHUR\\nHARRY POTTER\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nLOOKS LIKE\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE\\nZ\\xc3\\x9cRICH HAUPTBAHNHOF' (b'BAHNHOF\\t^\\t0.8254\\nWINTERTHUR\\t^\\t0.8501\\n\\nHARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nLOOKS\\tV\\t0.9878\\nLIKE\\tP\\t0.8516\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\nZ\\xc3\\x9cRICH\\t^\\t0.8980\\nHAUPTBAHNHOF\\t^\\t0.6175\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 16 tweets (37 tokens) in 0.4 seconds: 43.6 tweets/sec, 100.8 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'ALBERT EINSTEIN\\nBAHNHOF WINTERTHUR\\nHARRY POTTER\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nLOOKS LIKE\\nMARK TWAIN\\nMILA EURO\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRICHTIG ARSCH\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE\\nZ\\xc3\\x9cRICH HAUPTBAHNHOF' (b'ALBERT\\t^\\t0.9916\\nEINSTEIN\\t^\\t0.9579\\n\\nBAHNHOF\\t^\\t0.8254\\nWINTERTHUR\\t^\\t0.8501\\n\\nHARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nLOOKS\\tV\\t0.9878\\nLIKE\\tP\\t0.8516\\n\\nMARK\\t^\\t0.9835\\nTWAIN\\t^\\t0.9818\\n\\nMILA\\t^\\t0.9123\\nEURO\\t^\\t0.8809\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\nZ\\xc3\\x9cRICH\\t^\\t0.8980\\nHAUPTBAHNHOF\\t^\\t0.6175\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 19 tweets (43 tokens) in 0.4 seconds: 52.6 tweets/sec, 119.1 tokens/sec\\n')\n",
      "n_clusters: 20\n",
      "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1})\n",
      "sorted cluster [(0, 1)]\n",
      "b'ALBERT EINSTEIN\\nBAHNHOF BERN\\nBAHNHOF BERN GARE\\nBAHNHOF WINTERTHUR\\nBAHNHOFPLATZ BERN\\nBERN GARE\\nBERN GARE BERNE\\nBERN PIC\\nBOLLIGEN BOLLIGERSTRASSE\\nBOLLIGEN BOLLIGERSTRASSE BOLLIGEN\\nBOLLIGERSTRASSE BOLLIGEN\\nEBNER ESCHENBACH\\nGARE BERNE\\nHARRY POTTER\\nHENRY FORD\\nHEUTE RICHTIG\\nHEUTE RICHTIG ARSCH\\nHIGHLIGHTS ADD\\nJOHANN WOLFGANG\\nJOHANN WOLFGANG GOETHE\\nLOOKS LIKE\\nMAHATMA GANDHI\\nMARIE EBNER\\nMARIE EBNER ESCHENBACH\\nMARK TWAIN\\nMILA EURO\\nOKAY TWITTER\\nOKAY TWITTER SCHEINT\\nRBS BOLLIGEN\\nRBS BOLLIGEN BOLLIGERSTRASSE\\nRICHTIG ARSCH\\nROUTE MEYRIN\\nSCHEINT HEUTE\\nSCHEINT HEUTE RICHTIG\\nSEE HIGHLIGHTS\\nSEE HIGHLIGHTS ADD\\nTWITTER SCHEINT\\nTWITTER SCHEINT HEUTE\\nWOLFGANG GOETHE\\nZ\\xc3\\x9cRICH HAUPTBAHNHOF\\nZ\\xc3\\x9cRICH OTHERS' (b'ALBERT\\t^\\t0.9916\\nEINSTEIN\\t^\\t0.9579\\n\\nBAHNHOF\\t^\\t0.8731\\nBERN\\t^\\t0.9932\\n\\nBAHNHOF\\t^\\t0.8731\\nBERN\\t^\\t0.9960\\nGARE\\t^\\t0.5441\\n\\nBAHNHOF\\t^\\t0.8254\\nWINTERTHUR\\t^\\t0.8501\\n\\nBAHNHOFPLATZ\\t^\\t0.2276\\nBERN\\t^\\t0.9935\\n\\nBERN\\t^\\t0.9292\\nGARE\\t^\\t0.4204\\n\\nBERN\\t^\\t0.9292\\nGARE\\t^\\t0.6479\\nBERNE\\t^\\t0.9984\\n\\nBERN\\t^\\t0.9558\\nPIC\\tN\\t0.6287\\n\\nBOLLIGEN\\t^\\t0.2404\\nBOLLIGERSTRASSE\\t^\\t0.7907\\n\\nBOLLIGEN\\t^\\t0.2404\\nBOLLIGERSTRASSE\\t^\\t0.8309\\nBOLLIGEN\\t^\\t0.8850\\n\\nBOLLIGERSTRASSE\\t^\\t0.2010\\nBOLLIGEN\\t^\\t0.8288\\n\\nEBNER\\t^\\t0.6294\\nESCHENBACH\\t^\\t0.9287\\n\\nGARE\\t!\\t0.3540\\nBERNE\\t^\\t0.9198\\n\\nHARRY\\t^\\t0.9733\\nPOTTER\\t^\\t0.9940\\n\\nHENRY\\t^\\t0.9908\\nFORD\\t^\\t0.9972\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.6048\\n\\nHEUTE\\t^\\t0.3783\\nRICHTIG\\t^\\t0.7218\\nARSCH\\t^\\t0.9132\\n\\nHIGHLIGHTS\\tN\\t0.8597\\nADD\\tV\\t0.5615\\n\\nJOHANN\\t^\\t0.7200\\nWOLFGANG\\t^\\t0.8407\\n\\nJOHANN\\t^\\t0.7200\\nWOLFGANG\\t^\\t0.9150\\nGOETHE\\t^\\t0.9111\\n\\nLOOKS\\tV\\t0.9878\\nLIKE\\tP\\t0.8516\\n\\nMAHATMA\\t^\\t0.9296\\nGANDHI\\t^\\t0.9746\\n\\nMARIE\\t^\\t0.9893\\nEBNER\\t^\\t0.9577\\n\\nMARIE\\t^\\t0.9893\\nEBNER\\t^\\t0.9671\\nESCHENBACH\\t^\\t0.9531\\n\\nMARK\\t^\\t0.9835\\nTWAIN\\t^\\t0.9818\\n\\nMILA\\t^\\t0.9123\\nEURO\\t^\\t0.8809\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9936\\n\\nOKAY\\t!\\t0.9264\\nTWITTER\\t^\\t0.9952\\nSCHEINT\\t^\\t0.5115\\n\\nRBS\\t^\\t0.8424\\nBOLLIGEN\\t^\\t0.7223\\n\\nRBS\\t^\\t0.8424\\nBOLLIGEN\\t^\\t0.7794\\nBOLLIGERSTRASSE\\t^\\t0.8569\\n\\nRICHTIG\\t!\\t0.3198\\nARSCH\\t!\\t0.5046\\n\\nROUTE\\tN\\t0.9149\\nMEYRIN\\tN\\t0.4435\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9023\\n\\nSCHEINT\\t^\\t0.2012\\nHEUTE\\t^\\t0.9315\\nRICHTIG\\t^\\t0.7092\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.9208\\n\\nSEE\\tV\\t0.6673\\nHIGHLIGHTS\\tN\\t0.8892\\nADD\\tV\\t0.5524\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.4234\\n\\nTWITTER\\t^\\t0.9771\\nSCHEINT\\t^\\t0.6369\\nHEUTE\\t^\\t0.9343\\n\\nWOLFGANG\\t!\\t0.5164\\nGOETHE\\t!\\t0.7025\\n\\nZ\\xc3\\x9cRICH\\t^\\t0.8980\\nHAUPTBAHNHOF\\t^\\t0.6175\\n\\nZ\\xc3\\x9cRICH\\t^\\t0.9471\\nOTHERS\\tN\\t0.8699\\n\\n', b'Listening on stdin for input.  (-h for help)\\nDetected text input format\\nTokenized and tagged 41 tweets (93 tokens) in 0.4 seconds: 106.5 tweets/sec, 241.6 tokens/sec\\n')\n",
      "n_clusters: 3\n",
      "Counter({1: 20, 2: 17, 3: 16})\n",
      "sorted cluster [(2.65625, 3), (2.6470588235294117, 2), (0.66492244836163328, 1)]\n"
     ]
    }
   ],
   "source": [
    "tweet_old_time = -1\n",
    "window_analysis_time = 20  # This is the size of window that we analyze text inside it\n",
    "\n",
    "tid_to_raw_tweet = {}\n",
    "window_corpus = []\n",
    "tid_to_urls_window_corpus = {}\n",
    "tids_window_corpus = []\n",
    "dfVocTimeWindows = {}\n",
    "t = 0\n",
    "ntweets = 0\n",
    "for index, row in df.iterrows():\n",
    "    tweet_current_time = row['createdAt']\n",
    "    text = row['processed_text']\n",
    "    users = row['users']\n",
    "    hashtags = row['Hashtags']\n",
    "    if tweet_old_time == -1:\n",
    "        tweet_old_time = tweet_current_time\n",
    "    if (tweet_current_time - tweet_old_time).days < window_analysis_time: # Inside the window we still gather the data\n",
    "                                                                          # For analysis\n",
    "        ntweets += 1\n",
    "        [tokens, pos_tokens, entities, features] = nltk_tokenize(text)\n",
    "        tweet_bag = \"\"\n",
    "        try:\n",
    "            for user in set(users):\n",
    "                tweet_bag += \"@\" + user.decode('utf-8').lower() + \",\"\n",
    "            for tag in set(hashtags):\n",
    "                if tag.decode('utf-8').lower() not in stop_words: \n",
    "                    tweet_bag += \"#\" + tag.decode('utf-8').lower() + \",\"\n",
    "            for feature in features:\n",
    "                tweet_bag += feature + \",\"\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if len(users) < 3 and len(hashtags) < 3 and len(features) > 3 and len(tweet_bag.split(\",\")) > 4 \\\n",
    "                        and not str(features).upper() == str(features):\n",
    "\n",
    "            tweet_bag = tweet_bag[:-1]\n",
    "            window_corpus.append(tweet_bag)\n",
    "            tids_window_corpus.append(row.id)\n",
    "            tid_to_raw_tweet[row.id] = text\n",
    "    else:\n",
    "        tweet_old_time = tweet_current_time\n",
    "        #increase window counter used in df-idf\n",
    "        t += 1\n",
    "        # The reason for min_df is that the cluster need to gather enough tweet to be considered a topic\n",
    "        # CountVectorizer: Convert a collection of text documents to a matrix of token counts\n",
    "        vectorizer = CountVectorizer(tokenizer=custom_tokenize_text, binary=True,\\\n",
    "                            min_df=max(int(len(window_corpus)*0.0025), 10), ngram_range=(2,3))\n",
    "        try: # If the number of tweet is not enough\n",
    "             # vectorizer.fit_transform Learn the vocabulary dictionary and return term-document matrix.\n",
    "            X = vectorizer.fit_transform(window_corpus)\n",
    "        except:\n",
    "            continue\n",
    "        map_index_after_cleaning = {}\n",
    "        Xclean = np.zeros((1, X.shape[1]))\n",
    "        for i in range(0, X.shape[0]):\n",
    "            #keep sample with size at least 5\n",
    "            if X[i].sum() > 4:\n",
    "                Xclean = np.vstack([Xclean, X[i].toarray()])\n",
    "                map_index_after_cleaning[Xclean.shape[0] - 2] = i\n",
    "        Xclean = Xclean[1:,]\n",
    "        #print(\"total tweets in window:\", ntweets)\n",
    "        #print(\"X.shape:\", X.shape)\n",
    "        #print(\"Xclean.shape:\", Xclean.shape)\n",
    "        X = Xclean\n",
    "        Xdense = np.matrix(X).astype('float')\n",
    "        # doing some preprocessing to make the \n",
    "        #data suitable for machin learning algorithms\n",
    "        X_scaled = preprocessing.scale(Xdense)\n",
    "        X_normalized = preprocessing.normalize(X_scaled, norm='l2')\n",
    "        vocX = vectorizer.get_feature_names() # Array mapping from feature integer indices to feature name\n",
    "        boost_entity = {}\n",
    "        pos_tokens = CMUTweetTagger.runtagger_parse([term.upper() for term in vocX],\\\n",
    "                                           run_tagger_cmd=\"java -XX:ParallelGCThreads=2 -Xmx500m -jar data/ark-tweet-nlp-0.3.2.jar\")\n",
    "        \n",
    "\n",
    "        for l in pos_tokens:\n",
    "            term =''\n",
    "            for gr in range(0, len(l)):\n",
    "                term += l[gr][0].lower() + \" \"\n",
    "            if \"^\" in str(l):\n",
    "                boost_entity[term.strip()] = 2.5\n",
    "            else: \n",
    "                boost_entity[term.strip()] = 1.0\n",
    "        dfX = X.sum(axis=0)\n",
    "        dfVoc = {}\n",
    "        wdfVoc = {}\n",
    "        boosted_wdfVoc = {}\n",
    "        keys = vocX\n",
    "        vals = dfX\n",
    "        for k,v in zip(keys, vals):\n",
    "            dfVoc[k] = v\n",
    "        for k in dfVoc: \n",
    "            try:\n",
    "                dfVocTimeWindows[k] += dfVoc[k]\n",
    "                avgdfVoc = (dfVocTimeWindows[k] - dfVoc[k])/(t - 1)\n",
    "            except:\n",
    "                dfVocTimeWindows[k] = dfVoc[k]\n",
    "                avgdfVoc = 0\n",
    "            wdfVoc[k] = (dfVoc[k] + 1) / (np.log(avgdfVoc + 1) + 1)\n",
    "            try:\n",
    "                boosted_wdfVoc[k] = wdfVoc[k] * boost_entity[k]\n",
    "            except: \n",
    "                boosted_wdfVoc[k] = wdfVoc[k]\n",
    "        #print(\"sorted wdfVoc*boost_entity:\")\n",
    "        #print(sorted( ((v,k) for k,v in boosted_wdfVoc.items()), reverse=True))\n",
    "        distMatrix = pairwise_distances(X_normalized, metric='cosine')\n",
    "        L = fastcluster.linkage(distMatrix, method='average')\n",
    "        dt = 1  # distance threshold for clustering\n",
    "        indL = sch.fcluster(L, dt*distMatrix.max(), 'distance')\n",
    "        freqTwCl = Counter(indL)\n",
    "        print(\"n_clusters:\", len(freqTwCl))\n",
    "        print(freqTwCl)\n",
    "        npindL = np.array(indL)\n",
    "        freq_th = max(10, int(X.shape[0]*0.0025))\n",
    "        cluster_score = {}\n",
    "        for clfreq in freqTwCl.most_common(50):\n",
    "            cl = clfreq[0]\n",
    "            freq = clfreq[1]\n",
    "            cluster_score[cl] = 0\n",
    "            if freq >= freq_th:\n",
    "                clidx = (npindL == cl).nonzero()[0].tolist()\n",
    "                cluster_centroid = X[clidx].sum(axis=0)\n",
    "                try:\n",
    "                    cluster_tweet = vectorizer.inverse_transform(cluster_centroid)\n",
    "                    for term in np.nditer(cluster_tweet):\n",
    "                        try:\n",
    "                            cluster_score[cl] = max(cluster_score[cl], boosted_wdfVoc[str(term).strip()])\n",
    "                        except: pass\n",
    "                except: pass\n",
    "                cluster_score[cl] /= freq\n",
    "            else: break\n",
    "        sorted_clusters = sorted( ((v,k) for k,v in cluster_score.items()), reverse=True)\n",
    "        print(\"sorted cluster\",sorted_clusters)\n",
    "        ntopics = 20\n",
    "        headline_corpus = []\n",
    "        orig_headline_corpus = []\n",
    "        headline_to_cluster = {}\n",
    "        headline_to_tid = {}\n",
    "        cluster_to_tids = {}\n",
    "        for score,cl in sorted_clusters[:ntopics]:\n",
    "            clidx = (npindL == cl).nonzero()[0].tolist()\n",
    "            first_idx = map_index_after_cleaning[clidx[0]]\n",
    "            keywords = window_corpus[first_idx]\n",
    "            orig_headline_corpus.append(keywords)\n",
    "            headline = ''\n",
    "            for k in keywords.split(\",\"):\n",
    "                if not '@' in k and not '#' in k:\n",
    "                    headline += k + \",\"\n",
    "            headline_corpus.append(headline[:-1])\n",
    "            headline_to_cluster[headline[:-1]] = cl\n",
    "            headline_to_tid[headline[:-1]] = tids_window_corpus[first_idx]\n",
    "\n",
    "            tids = []\n",
    "            for i in clidx:\n",
    "                idx = map_index_after_cleaning[i]\n",
    "                tids.append(tids_window_corpus[idx])\n",
    "            cluster_to_tids[cl] = tids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RBS,Bolligen,Bolligerstrasse,Bolligen,pic': 148373869860884480,\n",
       " 'ja,mal,eher,hässlicher,Bahnhof,Bahnhof,Bern,Gare,Berne': 140348008280764416,\n",
       " 'okay,Twitter,scheint,heute,richtig,Arsch': 16201777044}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_to_tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indHL = sch.fcluster(HL, dtH*distH.max(), 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headline_vectorizer = CountVectorizer(tokenizer=custom_tokenize_text, binary=True, min_df=1, ngram_range=(1,1))\n",
    "H = headline_vectorizer.fit_transform(headline_corpus)\n",
    "print(\"H.shape:\", H.shape)\n",
    "vocH = headline_vectorizer.get_feature_names()\n",
    "\n",
    "Hdense = np.matrix(H.todense()).astype('float')\n",
    "distH = pairwise_distances(Hdense, metric='cosine')\n",
    "#\t\t\t\tprint \"fastcluster, avg, euclid\"\n",
    "HL = fastcluster.linkage(distH, method='average')\n",
    "dtH = 1.0\n",
    "indHL = sch.fcluster(HL, dtH*distH.max(), 'distance')\n",
    "freqHCl = Counter(indHL)\n",
    "print(\"hclust cut threshold:\", dtH)\n",
    "print(\"n_clusters:\", len(freqHCl))\n",
    "print(freqHCl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(CMUTweetTagger.runtagger_parse(['example tweet 1', 'example tweet 2'],\\\n",
    "                                     run_tagger_cmd=\"jar cmvf META-INF/MANIFEST.MF data/ark-tweet-nlp-0.3.2-sources.jar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
